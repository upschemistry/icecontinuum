{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480939ad",
   "metadata": {},
   "source": [
    "## Studying Growth Instability\n",
    "\n",
    "This code lets us explore how QLC-2 solutions vary with the following parameters:\n",
    "- $\\overline N$, and $N^*$ (atomistic-level characteristics of the ice QLL thicknesses)\n",
    "- $\\sigma_o$ (difference in equilibrium supersaturation between microsurfaces I and II)\n",
    "- $h_{pr}$ (thickness of a prismatic facet monolayer)\n",
    "- $D_{surf}$ (surface diffusion coefficient of the QLL)\n",
    "- $\\nu_{kin}$ (kinetic velocity -- the rate at which water vapor strikes the surface)\n",
    "- $L$ (physical length of the facet surface)\n",
    "- $nx_{crystal}$ (number of discrete points used to represent the surface)\n",
    "- $L$ (crystal dimension)\n",
    "- $\\sigma_{I,corner}$ (imposed supersaturation at the facet corner)\n",
    "- $c_r$ (relative reduction in supersaturation at facet centers relative to corners, in fraction and %)\n",
    "- $\\tau_{eq}$ (time constant for ice/QLL freezing/thawing)\n",
    "\n",
    "In addition, there's the possibility of activating the \"microsurface\" capablity, by specifying microsurfaces=1. In that case, additional parameters are needed:\n",
    "- $\\sigma_0$ multiplier (how the volatility of the pyramidal facet compares to that of the prismatic (>1 => less volatile)\n",
    "- $h_{py}$ multiplier (how the thickness of a pyramidal compares to that of the prismatic (>1 => thicker)\n",
    "- $N^*$ multiplier (how the variability of the pyramidal facet compares to that of the prismatic (>1 => more variable)\n",
    "- $\\theta$ (angle of the additional microfacet with respect to the prismatic (for pyramidal, this is 28 degrees)\n",
    "- $\\beta_{trans}$ multiplier (gradualness of transition between microfacet angles (smaller => more gradual))\n",
    "\n",
    "These are specified as small departures from a baseline scenario, taken from *Parameter Baseline*, which tries to come up with a self-consistent set of parameters at given values of:\n",
    "- $T$ (ambient temperature)\n",
    "- $P$ (ambient air pressure)\n",
    "- $\\sigma_{I,far}$ and $x_{far}$ (super/subsaturation of water vapor far from the crystal, and distance from the crystal at which $\\sigma_{I,far}$ is specified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2901602",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from pint import UnitRegistry; AssignQuantity = UnitRegistry().Quantity\n",
    "from importlib import reload\n",
    "from scipy import optimize\n",
    "from matplotlib import rcParams\n",
    "from scipy.fft import fft, ifft, rfft, irfft, fftfreq\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import QLCstuff as QLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac0690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "ticklabelsize = 15\n",
    "linewidth = 1\n",
    "fontsize = 15\n",
    "titlefontsize = 8\n",
    "color = 'k'\n",
    "markersize = 10\n",
    "\n",
    "# Preferred units\n",
    "distance_unit = 'micrometer'\n",
    "pressure_unit = 'pascal'\n",
    "time_unit = 'microsecond'\n",
    "temperature_unit = 'kelvin'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5367ad94",
   "metadata": {},
   "source": [
    "### Defining default parameters for runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3378d1bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nbar 1.0\n",
      "Nstar 0.1\n",
      "sigma0 = 0.2\n",
      "h_pr 0.389 nanometer\n",
      "D 0.000365 micrometer ** 2 / microsecond\n",
      "nu_kin 140 micrometer / second\n",
      "L 30 micrometer\n",
      "nx (crystal) 320\n",
      "sigmaI_corner 0.22 dimensionless\n",
      "c_r_percent 1.068 dimensionless\n",
      "tau_eq 10.0 microsecond\n"
     ]
    }
   ],
   "source": [
    "# Properties of the QLL\n",
    "Nbar = 1.0\n",
    "print('Nbar', Nbar)\n",
    "Nstar = 0.1\n",
    "print('Nstar', Nstar)\n",
    "\n",
    "# Difference in equilibrium supersaturation between microsurfaces I and II\n",
    "sigma0 = 0.2\n",
    "print('sigma0 =',sigma0)\n",
    "\n",
    "# Thickness of monolayers\n",
    "h_pr = AssignQuantity(0.389,'nanometer') # Prismatic facet as used in Neshyba et al 2016\n",
    "print('h_pr', h_pr)\n",
    "h_pr.ito('micrometer')\n",
    "\n",
    "# Diffusion coeficient\n",
    "D = AssignQuantity(3.65e-04,'micrometer^2/microsecond')\n",
    "print('D',D)\n",
    "\n",
    "# Kinetic velocity\n",
    "nu_kin = AssignQuantity(140,'micrometer/second')\n",
    "print('nu_kin', nu_kin)\n",
    "\n",
    "# Size of the facet\n",
    "L = AssignQuantity(30,'micrometer')\n",
    "print('L', L)\n",
    "\n",
    "# Crystal size -- needs to be an even number\n",
    "nx_crystal = 320 \n",
    "print('nx (crystal)', nx_crystal)\n",
    "\n",
    "# Supersaturation at the corner of a facet\n",
    "sigmaI_corner = AssignQuantity(0.22,'dimensionless') \n",
    "print('sigmaI_corner', sigmaI_corner)\n",
    "\n",
    "# Reduction of supersaturation at the facet cental\n",
    "c_r_percent = AssignQuantity(1.068,'dimensionless')\n",
    "print('c_r_percent',c_r_percent)\n",
    "\n",
    "# Time constant for freezing/thawing\n",
    "tau_eq = AssignQuantity(5.0,'microsecond')\n",
    "tau_eq = AssignQuantity(10.0,'microsecond')\n",
    "print('tau_eq',tau_eq)\n",
    "\n",
    "# Integration algorithm (other possibilities: RK23, DOP853, LSODA, and Radau)\n",
    "odemethod = 'RK45' # Explicit Runge-Kutta\n",
    "# odemethod = 'BDF' # Implicit multi-step variable-order (1 to 5) method (takes ~100x explicit methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc36312d",
   "metadata": {},
   "source": [
    "### Below are microfacet parameters (ignored if microfacets=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "760b39e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microfacets 1\n",
      "sigma0factor 1.1\n",
      "h_pyfactor 1\n",
      "Nstarfactor 0.7\n",
      "theta 30 degree\n",
      "beta_trans_factor 4\n"
     ]
    }
   ],
   "source": [
    "# Whether to use microfacets (0 => no microfaceting)\n",
    "microfacets = 1\n",
    "print('microfacets',microfacets)\n",
    "\n",
    "# How the volatility of the pyramidal facet compares to that of the prismatic (>1 => less volatile)\n",
    "sigma0factor = 1.1\n",
    "print('sigma0factor',sigma0factor)\n",
    "\n",
    "# How the pyramidal layer thickness compares to the prismatic (>1 => thicker)\n",
    "h_pyfactor = 1 \n",
    "print('h_pyfactor',h_pyfactor)\n",
    "\n",
    "# How the variability of the pyramidal facet compares to that of the prismatic (>1 => more variable)\n",
    "Nstarfactor = 0.7\n",
    "print('Nstarfactor',Nstarfactor)\n",
    "\n",
    "# Angle of the pyramidal facet\n",
    "theta = AssignQuantity(30, 'degrees')\n",
    "print('theta',theta)\n",
    "\n",
    "# Gradualness of transition between prismatic and pyramidal angles (smaller => more gradual)\n",
    "beta_trans_factor = 4\n",
    "print('beta_trans_factor',beta_trans_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20d84cb",
   "metadata": {},
   "source": [
    "### Varibles that depend on the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86ea70c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacing of points on the ice surface = 0.18808777429467227 micrometer\n"
     ]
    }
   ],
   "source": [
    "c_r = c_r_percent/100\n",
    "x_QLC = np.linspace(-L,L,nx_crystal)\n",
    "sigmaI_QLC = sigmaI_corner*(c_r*(x_QLC/L)**2+1-c_r)\n",
    "nu_kin_mlyperus = nu_kin/h_pr\n",
    "nu_kin_mlyperus.ito('1/microsecond')\n",
    "deltax = x_QLC[1]-x_QLC[0]\n",
    "print('Spacing of points on the ice surface =', deltax)\n",
    "Doverdeltax2 = D/deltax**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbd5b1d",
   "metadata": {},
   "source": [
    "### Run the scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a171b7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a run from time 20000.0 millisecond to 30000.0 millisecond\n",
      "dt = 101010.10101010278 microsecond\n",
      "Shape of the smooth list is  (3,)\n",
      "Shape of the smooth list is  (3,)\n",
      "Shape of the smooth list is  (3,)\n",
      "Shape of the smooth list is  (3,)\n",
      "Shape of the smooth list is  (3,)\n",
      "Shape of the smooth list is  (3,)\n",
      "Shape of the smooth list is  (3,)\n",
      "Shape of the smooth list is  (3,)\n",
      "Shape of the smooth list is  (3,)\n",
      "Shape of the smooth list is  (3,)\n",
      "Shape of the smooth list is  (3,)\n",
      "10 % elapsed time is 1.771 minutes\n",
      "Shape of the smooth list is  (3,)\n",
      "Shape of the smooth list is  (3,)\n",
      "Shape of the smooth list is  (3,)\n",
      "Shape of the smooth list is  (3,)\n"
     ]
    }
   ],
   "source": [
    "tlast = AssignQuantity(10000,'millisecond') # Use this line to override the estimated time\n",
    "tlast.ito('microsecond')\n",
    "\n",
    "# Number of time steps to keep for reporting later\n",
    "ntimes = 100\n",
    "\n",
    "fresh_run = False # If False, we're padding on to a previous execution of this cell\n",
    "if fresh_run:\n",
    "    tkeep_1Darr = np.linspace(0,tlast,ntimes)\n",
    "    Ntot_init_1D = np.ones(nx_crystal)\n",
    "    NQLL_init_1D = QLC.getNQLL(Ntot_init_1D,Nstar,Nbar)\n",
    "else:\n",
    "    tstart = tkeep_1Darr[-1]\n",
    "    tstop = tstart + tlast\n",
    "    tkeep_1Darr = np.linspace(tstart,tstop,ntimes)\n",
    "    Ntot_init_1D = Ntotkeep_1D[-1,:]\n",
    "    NQLL_init_1D = NQLLkeep_1D[-1,:]\n",
    "\n",
    "print('This is a run from time', tkeep_1Darr[0].to('msec'),'to', tkeep_1Darr[-1].to('msec'))\n",
    "print('dt =', tkeep_1Darr[1]-tkeep_1Darr[0])\n",
    "\n",
    "# Label for graphs\n",
    "title_params = \\\n",
    "        \"{:.0f}\".format(L.magnitude)+' '+str(L.units)+\\\n",
    "        \", \"+np.format_float_scientific(D.magnitude,precision=2)+\" \"+str(D.units)+\\\n",
    "        \"\\n\"+\\\n",
    "        \"{:.0f}\".format(nu_kin.magnitude)+' '+str(nu_kin.units)+\\\n",
    "        \"\\n\"+\\\n",
    "        \"{:.3f}\".format(sigmaI_corner.magnitude)+' '+str(sigmaI_corner.units)+\\\n",
    "        \", \"+\"{:.1f}\".format(tau_eq.magnitude)+' '+str(tau_eq.units)+\\\n",
    "        \", \"+\"{:.3f}\".format(c_r_percent.magnitude)+'%'+\\\n",
    "        \", \"+odemethod+\\\n",
    "        \"\\n\"\n",
    "    \n",
    "# Solve the 1-D problem\n",
    "Ntotkeep_1D, NQLLkeep_1D = QLC.run_pypr(\\\n",
    "                    NQLL_init_1D, Ntot_init_1D, tkeep_1Darr,\\\n",
    "                    Nbar, Nstar, sigma0, nu_kin_mlyperus, Doverdeltax2, tau_eq, \\\n",
    "                    theta, beta_trans_factor, Nstarfactor, h_pr, h_pyfactor, sigma0factor,\\\n",
    "                    sigmaI_QLC, x_QLC,\n",
    "                    AssignQuantity,\\\n",
    "                    verbose=0, odemethod=odemethod, microfacets=microfacets)\n",
    "Nicekeep_1D = Ntotkeep_1D-NQLLkeep_1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12e7393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = np.array([[[]]])\n",
    "# print(tmp)\n",
    "# print(tmp.shape)\n",
    "# print(len(tmp))\n",
    "# print()\n",
    "# tmp = np.squeeze(tmp)\n",
    "# print(tmp)\n",
    "# print(tmp.shape)\n",
    "# print(len(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0518ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp = np.array([1,2,2])\n",
    "# itmplist = np.argwhere(tmp==2)\n",
    "# print(itmplist)\n",
    "# itmplist = itmplist.reshape(-1)\n",
    "# #print(itmplist)\n",
    "# for itmp in itmplist:\n",
    "#     print(itmp, type(itmp))\n",
    "#     print(tmp[itmp])\n",
    "#     print(tmp[itmp-1:itmp+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ac3f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reporting and graphing\n",
    "g_ice_QLC = QLC.report_1d_growth_results(\\\n",
    "        x_QLC,tkeep_1Darr,NQLLkeep_1D,Ntotkeep_1D,Nicekeep_1D,h_pr, \\\n",
    "        graphics=True,title_params=title_params)\n",
    "\n",
    "# This is only of interest if we're looking at the \"sticking\" coefficient\n",
    "alpha_sticking = g_ice_QLC/(sigmaI_corner*nu_kin)\n",
    "alpha_sticking = AssignQuantity(alpha_sticking,'dimensionless')\n",
    "print('alpha_sticking relative to sigmaI_corner =',alpha_sticking)\n",
    "\n",
    "# Additional graphing\n",
    "plt.figure()\n",
    "plt.plot(x_QLC.magnitude,sigmaI_QLC.magnitude*100)\n",
    "plt.grid(True)\n",
    "plt.xlabel('$x \\ (\\mu m)$',fontsize=fontsize)\n",
    "plt.ylabel('$\\sigma \\ (\\%)$',fontsize=fontsize)\n",
    "rcParams['xtick.labelsize'] = ticklabelsize \n",
    "rcParams['ytick.labelsize'] = ticklabelsize\n",
    "plt.title(title_params,fontsize=titlefontsize)\n",
    "\n",
    "# Ntot in micrometers (instead of layers)\n",
    "plt.figure()\n",
    "ydiff = Ntotkeep_1D[-1,:]*h_pr\n",
    "ydiff = ydiff - np.min(ydiff)\n",
    "plt.plot(x_QLC.magnitude,ydiff.magnitude)\n",
    "plt.grid(True)\n",
    "plt.xlabel('$x \\ (\\mu m)$',fontsize=fontsize)\n",
    "plt.ylabel('Thickness ($\\mu m)$',fontsize=fontsize)\n",
    "\n",
    "# Check out symmetry\n",
    "itime = -1\n",
    "thisNQLL = NQLLkeep_1D[itime,:]\n",
    "thisNQLL_flipped = np.flip(thisNQLL)\n",
    "plt.figure()\n",
    "plt.plot(x_QLC.magnitude,(thisNQLL_flipped-thisNQLL))\n",
    "plt.xlabel('$x \\ (\\mu m)$',fontsize=fontsize)\n",
    "plt.grid(True)\n",
    "plt.title('QLL symmetry check',fontsize=titlefontsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc17bbbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check out intermediate values\n",
    "for itime in range(ntimes-1,0,-20):\n",
    "    title_params = str(itime)+' ('+str(tkeep_1Darr[itime].to('millisecond'))+')'\n",
    "    g_ice_QLC = QLC.report_1d_growth_results(\\\n",
    "        x_QLC,tkeep_1Darr,NQLLkeep_1D,Ntotkeep_1D,Nicekeep_1D,h_pr, \\\n",
    "        graphics=True,tgraphics=False,title_params=title_params,itime=itime, \\\n",
    "        xlim=[-30,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ced820",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Probing properties of multiple facet types\n",
    "if microfacets == 1:\n",
    "    from scipy.interpolate import CubicSpline\n",
    "#     from scipy.interpolate import Akima1DInterpolator\n",
    "#     from scipy.interpolate import PchipInterpolator\n",
    "    myinterpolator = CubicSpline\n",
    "    itime = -1\n",
    "    print('Probing itime =',itime)\n",
    "    print('Probing time =',tkeep_1Darr[itime].to('millisecond'))\n",
    "    Ntot_pr = Ntotkeep_1D[itime,:]\n",
    "    NQLL_pr = NQLLkeep_1D[itime,:]\n",
    "    xleft = -L.magnitude\n",
    "    xright = L.magnitude\n",
    "\n",
    "    # Seeing how to smooth out point with large second derivative\n",
    "#     def smoothout(x_QLC,Ntot_pr,deltax,d2Ntot_dx2_threshold):\n",
    "#         dNtot_dx = np.gradient(Ntot_pr,deltax)#; print(dNtot_dx.units)\n",
    "#         d2Ntot_dx2 = np.gradient(dNtot_dx,deltax)#; print(d2Ntot_dx2.units)\n",
    "#         ismoothlist = np.argwhere(d2Ntot_dx2<-d2Ntot_dx2_threshold)\n",
    "#         ismoothlist = np.squeeze(ismoothlist)#; print(ismoothlist)\n",
    "#         Ntot_pr_smoothed = np.copy(Ntot_pr)\n",
    "#         nbefore = 2; #print(nbefore)\n",
    "#         nafter = nbefore+1; #print(nafter)\n",
    "        \n",
    "#         for ismooth in ismoothlist:\n",
    "#             if ismooth < nbefore:\n",
    "#                 print(\"Can't smooth at the beginning of the Ntot array\")\n",
    "#             elif ismooth > len(x_QLC)-nafter:\n",
    "#                 print(\"Can't smooth at the end of the Ntot array\")\n",
    "#             else:\n",
    "#                 x = x_QLC[ismooth-nbefore:ismooth+nafter].magnitude; #print(\"here is x\", x)\n",
    "#                 x = np.delete(x,nbefore); #print(\"here is x\", x)\n",
    "#                 y = Ntot_pr[ismooth-nbefore:ismooth+nafter]; #print(\"here is y\",y)\n",
    "#                 y = np.delete(y,nbefore); #print(\"here is y\", y)\n",
    "#                 spl = myinterpolator(x,y)\n",
    "#                 ynew = spl(x[nbefore]) # same as spl(x_QLC[ismooth])\n",
    "#                 #print('Replacing ',Ntot_pr[ismooth],'with', ynew)\n",
    "#                 Ntot_pr_smoothed[ismooth] = ynew\n",
    "#         return d2Ntot_dx2, Ntot_pr_smoothed\n",
    "\n",
    "#     d2Ntot_dx2_threshold = AssignQuantity(10000,d2Ntot_dx2.units)\n",
    "#     d2Ntot_dx2, Ntot_pr_smoothed = smoothout(x_QLC,Ntot_pr,deltax,d2Ntot_dx2_threshold)\n",
    "#     plt.figure()\n",
    "#     plt.plot(x_QLC,d2Ntot_dx2.magnitude/1e3)\n",
    "#     plt.grid(True)\n",
    "#     plt.ylabel(r'$d^2N_{tot}/dx^2$')\n",
    "#     plt.xlim([xleft,xright])\n",
    "#     plt.figure()\n",
    "#     plt.plot(x_QLC,Ntot_pr,'-+',label='orig')\n",
    "#     plt.plot(x_QLC,Ntot_pr_smoothed,label='smoothed')\n",
    "#     plt.ylabel(r'$N_{tot}$')\n",
    "#     plt.legend()\n",
    "#     plt.xlim([xleft,xright])\n",
    "#     Ntot_pr = np.copy(Ntot_pr_smoothed)\n",
    "    \n",
    "#     # Again\n",
    "#     d2Ntot_dx2_threshold = AssignQuantity(50,d2Ntot_dx2.units)\n",
    "#     d2Ntot_dx2, Ntot_pr_smoothed = smoothout(x_QLC,Ntot_pr,deltax,d2Ntot_dx2_threshold)\n",
    "#     plt.figure()\n",
    "#     plt.plot(x_QLC,d2Ntot_dx2.magnitude/1e3)\n",
    "#     plt.grid(True)\n",
    "#     plt.ylabel(r'$d^2N_{tot}/dx^2$')\n",
    "#     plt.xlim([xleft,xright])\n",
    "#     plt.figure()\n",
    "#     plt.plot(x_QLC,Ntot_pr,'-+',label='orig')\n",
    "#     plt.plot(x_QLC,Ntot_pr_smoothed,label='smoothed')\n",
    "#     plt.ylabel(r'$N_{tot}$')\n",
    "#     plt.legend()\n",
    "#     plt.xlim([xleft,xright])\n",
    "#     Ntot_pr = np.copy(Ntot_pr_smoothed)\n",
    "    \n",
    "\n",
    "    # Specifying how to partition among the three facets\n",
    "    beta_trans = np.sin(theta/2)/np.cos(theta/2)\n",
    "    print('beta_trans =', beta_trans)\n",
    "    delta_beta = beta_trans/beta_trans_factor\n",
    "    print('delta_beta',delta_beta)\n",
    "\n",
    "    # Now we'll work with the Ntot data of interest\n",
    "    h_py = h_pr*h_pyfactor\n",
    "    Ntot_pyneg = 1/h_py * (np.cos(theta)*h_pr* Ntot_pr -np.sin(theta)*x_QLC)\n",
    "    Ntot_pypos = 1/h_py * (np.cos(theta)*h_pr* Ntot_pr +np.sin(theta)*x_QLC)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x_QLC,Ntot_pr,label='prismatic')\n",
    "    # plt.plot(x_QLC,Ntot_pyneg,label='negative-sloped '+str(theta))\n",
    "    # plt.plot(x_QLC,Ntot_pypos,label='positive-sloped '+str(theta))\n",
    "    plt.xlabel('x',fontsize=fontsize)\n",
    "    plt.ylabel('Ntot',fontsize=fontsize)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.xlim([xleft,xright])\n",
    "\n",
    "    z_pr = h_pr * Ntot_pr\n",
    "    dx = x_QLC[1]-x_QLC[0]\n",
    "    beta = np.gradient(z_pr,dx)\n",
    "    beta.ito('dimensionless')\n",
    "    alpha_pyneg = QLC.get_alpha(beta.magnitude,-beta_trans.magnitude,delta_beta.magnitude)\n",
    "    alpha_pypos = 1-QLC.get_alpha(beta.magnitude, beta_trans.magnitude,delta_beta.magnitude)\n",
    "    alpha_pr = 1 - alpha_pyneg - alpha_pypos\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x_QLC,alpha_pr,label='prismatic')\n",
    "    plt.plot(x_QLC,alpha_pyneg,label='negative-sloped '+str(theta.to('degree')))\n",
    "    plt.plot(x_QLC,alpha_pypos,label='positive-sloped '+str(theta.to('degree')))\n",
    "    plt.xlabel('x',fontsize=fontsize)\n",
    "    plt.ylabel(r'$\\alpha$',fontsize=fontsize)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlim([xleft,xright])\n",
    "\n",
    "    Nstar_pr = Nstar\n",
    "    Nstar_py = Nstar_pr*Nstarfactor; print(Nstar_py)\n",
    "    NQLL_eq_pr    = Nbar - Nstar_pr*np.sin(2*np.pi*Ntot_pr)\n",
    "    NQLL_eq_pyneg = Nbar - Nstar_py*np.sin(2*np.pi*Ntot_pyneg)\n",
    "    NQLL_eq_pypos = Nbar - Nstar_py*np.sin(2*np.pi*Ntot_pypos)\n",
    "    NQLL_eq = alpha_pr*NQLL_eq_pr + alpha_pyneg*NQLL_eq_pyneg + alpha_pypos*NQLL_eq_pypos\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(x_QLC,NQLL_eq_pr,label='prismatic')\n",
    "    # plt.plot(x_QLC,NQLL_eq_pyneg,label='negative-sloped '+str(theta))\n",
    "    # plt.plot(x_QLC,NQLL_eq_pypos,label='positive-sloped '+str(theta))\n",
    "    plt.plot(x_QLC,NQLL_eq,label='combined')\n",
    "    plt.xlabel('x',fontsize=fontsize)\n",
    "    plt.ylabel('NQLL(eq)',fontsize=fontsize)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlim([xleft,xright])\n",
    "\n",
    "    # slopes = dx.magnitude*np.ones(len(x_QLC)) + 1j*beta.magnitude*dx.magnitude\n",
    "    slopes = np.ones(len(x_QLC)) + 1j*beta.magnitude\n",
    "    angles = AssignQuantity(np.angle(slopes),'radian')\n",
    "    angles.ito('degree')\n",
    "\n",
    "    plt.figure()\n",
    "    if (np.max(np.abs(angles.magnitude)) > 0.1):\n",
    "        plt.plot(x_QLC,angles.magnitude)\n",
    "        plt.xlabel('x',fontsize=fontsize)\n",
    "        plt.ylabel(r'pixel $\\theta$ ('+str(angles.units)+')',fontsize=fontsize)\n",
    "    else:\n",
    "        plt.plot(x_QLC,angles.magnitude*500)\n",
    "        plt.xlabel('x',fontsize=fontsize)\n",
    "        plt.ylabel(r'pixel $\\theta$ ('+str(angles.units)+'*1000)',fontsize=fontsize)\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.xlim([xleft,xright])\n",
    "    \n",
    "    # The corrected diffusion coefficient\n",
    "    Doverdeltay2 = Doverdeltax2*np.cos(angles)\n",
    "    plt.figure()\n",
    "    plt.plot(x_QLC,Doverdeltax2.magnitude*np.ones(len(x_QLC))*deltax**2*1e3,label='D x 1000')\n",
    "    plt.plot(x_QLC,Doverdeltay2.magnitude*deltax**2*1e3,label='corrected')\n",
    "    plt.grid(True)\n",
    "    plt.xlim([xleft,xright])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e057b639",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def smoothout(x_QLC,Ntot_pr,deltax,d2Ntot_dx2_threshold):\n",
    "#         dNtot_dx = np.gradient(Ntot_pr,deltax)#; print(dNtot_dx.units)\n",
    "#         d2Ntot_dx2 = np.gradient(dNtot_dx,deltax)#; print(d2Ntot_dx2.units)\n",
    "#         ismoothlist = np.argwhere(d2Ntot_dx2<-d2Ntot_dx2_threshold)\n",
    "#         ismoothlist = np.squeeze(ismoothlist)#; print(ismoothlist)\n",
    "# #         ismoothlist = [317]\n",
    "#         Ntot_pr_smoothed = np.copy(Ntot_pr)\n",
    "#         nbefore = 2; #print(nbefore)\n",
    "#         nafter = nbefore+1; #print(nafter)\n",
    "        \n",
    "#         for ismooth in ismoothlist:\n",
    "#             if ismooth < nbefore:\n",
    "#                 print(\"Can't smooth at the beginning of the Ntot array\")\n",
    "#             elif ismooth > len(x_QLC)-nafter:\n",
    "#                 print(\"Can't smooth at the end of the Ntot array\")\n",
    "#             else:\n",
    "#                 x = x_QLC[ismooth-nbefore:ismooth+nafter]#; print(\"here is x\", x)\n",
    "#                 y = Ntot_pr[ismooth-nbefore:ismooth+nafter]#; print(\"here is y\",y)\n",
    "#                 spl = CubicSpline(x, y)     \n",
    "#                 Ntot_pr_smoothed[ismooth] = spl(x_QLC[ismooth])\n",
    "#         return d2Ntot_dx2, Ntot_pr_smoothed\n",
    "\n",
    "# d2Ntot_dx2_threshold = AssignQuantity(10000,d2Ntot_dx2.units)\n",
    "# d2Ntot_dx2, Ntot_pr_smoothed = smoothout(x_QLC.magnitude,Ntot_pr,deltax,d2Ntot_dx2_threshold)\n",
    "\n",
    "# # print(len(x_QLC))\n",
    "# # print(len(x_QLC)-nbefore)\n",
    "# # ismooth = 317\n",
    "# # x = x_QLC[ismooth-nbefore:ismooth+nafter+1]\n",
    "# # y = x_QLC[ismooth-nbefore:ismooth+nafter+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a451a3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is just to get a visual on the partitioning among the three facets (alpha)\n",
    "# beta = np.linspace(-beta_trans*2,beta_trans*2,500)\n",
    "# delta_beta = beta_trans/5\n",
    "# alpha_pyneg = QLC.get_alpha(beta,-beta_trans,delta_beta)\n",
    "# alpha_pypos = 1-QLC.get_alpha(beta, beta_trans,delta_beta)\n",
    "# alpha_pr = 1 - alpha_pyneg - alpha_pypos\n",
    "# plt.figure()\n",
    "# plt.plot(beta,alpha_pr,label='prismatic')\n",
    "# plt.plot(beta,alpha_pyneg,label='negative-sloped '+str(theta))\n",
    "# plt.plot(beta,alpha_pypos,label='positive-sloped '+str(theta))\n",
    "# plt.xlabel(r'$\\beta$')\n",
    "# plt.ylabel(r'$\\alpha$')\n",
    "# plt.grid(True)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635bf5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# plt.plot(x_QLC,NQLL_eq-NQLL_eq_pr,label='combined-'+str(theta))\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('NQLL(eq)')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.xlim([xleft,xright])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb2f4e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# m_actual = (NQLL_pr-(Nbar-Nstar))/(2*Nstar)\n",
    "# sigma_m_actual = sigmaI_QLC - m_actual * sigma0\n",
    "# Nstar_est = alpha_pr*Nstar_pr + alpha_pyneg*Nstar_py + alpha_pypos*Nstar_py\n",
    "# m_predicted = (NQLL_pr -(Nbar-Nstar_est))/(2*Nstar_est)\n",
    "# sigma_m_predicted = sigmaI_QLC - m_predicted * sigma0\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(x_QLC,sigma_m_actual*100,label='actual')\n",
    "# plt.plot(x_QLC,sigma_m_predicted*100,label='predicted')\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel(r'$\\sigma_m$ (%)')\n",
    "# plt.grid(True)\n",
    "# plt.legend()\n",
    "# plt.xlim([xleft,xright])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239760b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is testing how to take a 1st derivative using FT\n",
    "\n",
    "# Z_pr = rfft(z_pr.magnitude)\n",
    "# j_list = np.array([j for j in range(len(Z_pr))])\n",
    "# dZpr_dx = 1j*Z_pr*j_list\n",
    "# dzpr_dx = np.real(irfft(dZpr_dx))*np.pi/L.magnitude\n",
    "\n",
    "# dx = x_QLC[1]-x_QLC[0]\n",
    "# dzpr_dx_diff = np.diff(z_pr)/dx\n",
    "# plt.figure()\n",
    "# plt.plot(x_QLC,dzpr_dx,label='FT')\n",
    "# # plt.plot(x_QLC[1:],dzpr_dx_diff,label='diff')\n",
    "# plt.plot(x_QLC,beta,label='gradient')\n",
    "# plt.grid(True)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235dec5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # This is testing how to take a 1st derivative using FT\n",
    "\n",
    "# xmax = 2\n",
    "# npts = 500\n",
    "# x_long = np.linspace(-xmax,xmax,npts+1)\n",
    "# x = x_long[0:-1]\n",
    "# x = (x_long[1:]+x_long[0:-1])/2\n",
    "# print(len(x))\n",
    "# dx = x[1]-x[0]; print(dx)\n",
    "# dummy = np.cos(x*2*np.pi/.5)\n",
    "# plt.figure()\n",
    "# plt.plot(x,dummy)\n",
    "\n",
    "# Dummy = np.real(rfft(dummy))\n",
    "# j_list = np.array([j for j in range(len(Dummy))])\n",
    "# scalefactor = np.pi/xmax\n",
    "# dDummy_dx = 1j*Dummy*j_list\n",
    "# ddummy_dx = np.real(irfft(dDummy_dx)) * scalefactor\n",
    "\n",
    "# ddummy_dx_diff = np.diff(dummy) / dx\n",
    "# plt.figure()\n",
    "# plt.plot(x,ddummy_dx,label='FT')\n",
    "# plt.plot(x[1:],ddummy_dx_diff,label='diff')\n",
    "# plt.legend()\n",
    "\n",
    "# testfactor = np.median(ddummy_dx[1:]/ddummy_dx_diff)\n",
    "# print(testfactor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cd7379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, trying to symmetrize x_QLC with correct boundary conditions\n",
    "\n",
    "# print(nx_crystal)\n",
    "# x_QLC_long = np.linspace(-L,L,nx_crystal+1)\n",
    "# print(len(x_QLC_long))\n",
    "# print(x_QLC_long[-1])\n",
    "\n",
    "# x_QLC = x_QLC_long[0:-1]\n",
    "# print(len(x_QLC))\n",
    "# print(x_QLC[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a1673e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameterlist_mag = []\n",
    "\n",
    "# # The following notes are based on np.gradient for calculating beta\n",
    "\n",
    "# # 1. Baseline\n",
    "# # parameterlist_mag.append(\n",
    "# #     [L.magnitude, D.magnitude, nu_kin.magnitude, \n",
    "# #      sigmaI_corner, c_r_percent.magnitude, tau_eq.magnitude])\n",
    "# # Results: ... \n",
    "\n",
    "# # 2. Higher nu_kin and bigger tau\n",
    "# # parameterlist_mag.append(\n",
    "# #     [L.magnitude, D.magnitude, 140, \n",
    "# #      sigmaI_corner, c_r_percent.magnitude, 5])\n",
    "# # Results: Nice microfaceting at intervals of 5-10 micrometers. However, there are two spikes that I don't like\n",
    "# # at 10,000 ms\n",
    "\n",
    "# # 2-1. Like #2, but with a lower sigmaI_corner\n",
    "# # parameterlist_mag.append(\n",
    "# #     [L.magnitude, D.magnitude, 140, \n",
    "# #      0.213, c_r_percent.magnitude, 5])\n",
    "# # Results: Nice microfaceting at intervals of 5-10 micrometers. However, there are several spikes that I don't like.\n",
    "\n",
    "# # 2-2. Like #2, but with a higher sigmaI_corner\n",
    "# parameterlist_mag.append(\n",
    "#     [L.magnitude, D.magnitude, 140, \n",
    "#      0.26, c_r_percent.magnitude, 5])\n",
    "# # Results: I was hoping this will remove the spikes. Twice submitted, the kernel dies at 12,000 ms. \n",
    "# # So submitting it for 10,000 ms, but there's still a spike.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 2-2. Like #2, but with a pyramidal facet that is more volatile than the prismatic\n",
    "# # sigma0factor = 0.9; print('sigma0factor',sigma0factor)\n",
    "# # parameterlist_mag.append(\n",
    "# #     [L.magnitude, D.magnitude, 140, \n",
    "# #      sigmaI_corner, c_r_percent.magnitude, 5])\n",
    "# # Results: ...\n",
    "\n",
    "# # 2-3. Higher nu_kin and bigger tau\n",
    "# # parameterlist_mag.append(\n",
    "# #     [L.magnitude, D.magnitude, 140, \n",
    "# #      sigmaI_corner, c_r_percent.magnitude, 5])\n",
    "# # Results: ...\n",
    "\n",
    "\n",
    "\n",
    "# print(parameterlist_mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa828cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
